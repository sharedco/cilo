# PRD: Cilo Cloud â€” Isolated Dev Environments, Locally or Remotely

## Status: Draft
## Author: Engineering
## Last Updated: 2026-02-07

---

## 1. What Cilo Is

Cilo creates isolated copies of your application â€” each with its own network, DNS, and state â€” and runs them locally or on remote infrastructure. One command, zero config changes.

```bash
cilo up agent-1                        # Local: isolated copy on your laptop
cilo cloud up agent-1 --from .         # Remote: isolated copy on a server
```

Both produce the same result: every service addressable by name (`api.agent-1.test`), fully isolated from every other environment. Your application code doesn't change. Your config files don't change. Cilo figures out the rest.

### What Cilo Does

1. **Detects** your project format (Compose, devcontainer, Procfile)
2. **Isolates** it (unique network, unique DNS, no port conflicts)
3. **Runs** it (locally via Docker/Podman, or remotely on any server)
4. **Addresses** every service by name (`<service>.<env>.test`)

### What Cilo Isn't

Cilo is not an IDE, a deployment platform, or a Kubernetes abstraction. It doesn't replace your editor, your CI pipeline, or your production infrastructure. It runs your dev environment â€” wherever you want â€” and gets out of the way.

---

## 2. Positioning

### The Problem

Developers need isolated copies of their application. For PR previews, for parallel AI agents, for onboarding, for testing. The existing tools either require Kubernetes knowledge (Coder, Shipyard), platform lock-in (Codespaces, Vercel), or only handle frontend (Netlify, Vercel).

Teams with 5-50 developers and no platform engineering team are underserved. They have a `docker-compose.yml` (or a `devcontainer.json`, or a `Procfile`) that works. They want to run it remotely without learning Terraform, Kubernetes, or a new platform config language.

### The Positioning

**Isolated dev environments for any project â€” locally or remotely.**

Not "simpler Coder." Not "preview environments." Not "agent infrastructure." All of those are use cases. The product is the isolation engine.

```
What you do with it:                 All the same operation:
â”œâ”€â”€ PR preview environments          cilo cloud up pr-42 --from .
â”œâ”€â”€ Parallel AI agent workspaces     cilo run claude agent-1 "task" --cloud
â”œâ”€â”€ Onboard a new developer          cilo cloud up sarah-dev --from .
â”œâ”€â”€ Offload heavy services           cilo cloud up ml-training --from .
â””â”€â”€ Isolated CI test runs            cilo cloud up ci-$RUN_ID --ci --from .
```

### Why Cilo vs Alternatives

| | Cilo | Coder | Shipyard | Vercel |
|---|---|---|---|---|
| Input format | Your existing files (auto-detected) | Terraform templates | Docker Compose â†’ K8s | Framework-specific |
| Local environments | Yes (core feature) | No | No | No |
| Remote environments | Yes | Yes | Yes | Yes (frontend only) |
| Requires K8s knowledge | No | Yes | Hidden but yes | No |
| Self-hostable | Yes (open source) | Yes (AGPL) | No | No |
| Platform team required | No | Effectively yes | No | No |
| Full-stack (DB, workers, etc.) | Yes | Yes | Yes | No |

**Cilo's unique position:** The only tool that does local + remote isolation from existing project files, without requiring Kubernetes, Terraform, or platform lock-in.

### Competitive Context

**Coder** ($76M raised, 50M+ downloads) is the incumbent in remote dev environments. Terraform-based, Kubernetes-native, built for platform teams at 500+ developer organizations. Cilo serves teams that don't have (and don't want) a platform team. Coder is the enterprise play; Cilo is the developer play. These audiences overlap at the margins but the core buyers are different.

**Shipyard** is the closest direct competitor for preview environments. They accept Docker Compose but transpile it to Kubernetes. Not self-hostable. Cilo runs Compose natively and can be self-hosted.

**Vercel/Netlify** own frontend previews. Cilo handles the full stack â€” databases, workers, queues, ML services â€” which Vercel can't.

**Bunnyshell/Qovery/Release** are full PaaS platforms with preview features. They require adopting their platform config. Cilo works with what you already have.

### Distribution: Local â†’ Remote â†’ Hosted

The adoption funnel is the product itself:

```
Free: Local isolation (existing Cilo CLI, open source)
  â†“ laptop runs out of resources / need to share environments
Self-host: Remote environments on your own servers
  â†“ don't want to manage servers / want pre-warmed pools
Hosted: cilocloud.dev manages everything
```

Each step is a natural response to a real pain point. The local experience is the top of the funnel. The hosted product is the monetization layer.

---

## 3. Architecture

### 3.1 Core Abstraction: Parser + Runtime

Cilo's engine is format-agnostic. It detects your project type, parses it into a universal environment spec, and runs it on the appropriate runtime. This is the architectural decision that prevents Compose lock-in.

```go
// pkg/engine/spec.go â€” The universal environment description

type EnvironmentSpec struct {
    Name     string
    Services []ServiceSpec
    Networks []NetworkSpec
    Volumes  []VolumeSpec
    Source   string          // "compose", "devcontainer", "procfile"
}

type ServiceSpec struct {
    Name       string
    Image      string              // Container image
    Build      *BuildSpec          // Build context (if no pre-built image)
    Command    []string
    Ports      []PortSpec
    Env        map[string]string
    Volumes    []VolumeMountSpec
    DependsOn  []string
    HealthCheck *HealthCheckSpec
}
```

```go
// pkg/engine/parser.go â€” Pluggable format detection

type Parser interface {
    Detect(projectPath string) bool
    Parse(projectPath string) (*EnvironmentSpec, error)
}

// Detection order: most specific â†’ least specific
var Parsers = []Parser{
    &ComposeParser{},        // docker-compose.yml, compose.yml
    &DevcontainerParser{},   // .devcontainer/devcontainer.json
    &ProcfileParser{},       // Procfile
}

func DetectAndParse(projectPath string) (*EnvironmentSpec, error) {
    for _, p := range Parsers {
        if p.Detect(projectPath) {
            return p.Parse(projectPath)
        }
    }
    return nil, fmt.Errorf("no supported project format found in %s", projectPath)
}
```

```go
// pkg/engine/runtime.go â€” Pluggable container runtime

type Runtime interface {
    Up(spec *EnvironmentSpec, env string) error
    Down(env string) error
    Destroy(env string) error
    Status(env string) ([]ServiceStatus, error)
    Logs(env string, service string) (io.ReadCloser, error)
}

// Implementations
type DockerRuntime struct{}    // Docker Engine + Compose plugin
type PodmanRuntime struct{}    // Podman + podman-compose
```

**Auto-detection in practice:**

```bash
cilo up agent-1
# Found docker-compose.yml â†’ ComposeParser + DockerRuntime âœ“

cilo up agent-1
# Found .devcontainer/devcontainer.json â†’ DevcontainerParser + DockerRuntime âœ“

cilo up agent-1
# Found Procfile â†’ ProcfileParser + DockerRuntime (auto-containerize) âœ“
```

### 3.2 Format Support Roadmap

| Format | Parser | Phase | Market |
|--------|--------|-------|--------|
| Docker Compose | `ComposeParser` | **Now (exists)** | Largest installed base for local dev |
| Podman runtime | `PodmanRuntime` | **Phase 2** | Enterprise (Red Hat, Docker licensing) |
| Devcontainer | `DevcontainerParser` | **Phase 4** | Codespaces/Cursor users, growing fast |
| Procfile | `ProcfileParser` | **Phase 6+** | Non-containerized apps, widest reach |

Compose is first because it's the largest market and Cilo already supports it. But the architecture doesn't trap us there. Adding a new format means implementing one interface.

### 3.3 Monorepo Structure

```
github.com/sharedco/cilo/
â”œâ”€â”€ cilo/                          # CLI (MIT)
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â”œâ”€â”€ root.go
â”‚   â”‚   â”œâ”€â”€ up.go                   # cilo up (local)
â”‚   â”‚   â”œâ”€â”€ run.go
â”‚   â”‚   â”œâ”€â”€ lifecycle.go
â”‚   â”‚   â”œâ”€â”€ cloud.go                # cilo cloud subcommand group
â”‚   â”‚   â”œâ”€â”€ cloud_login.go
â”‚   â”‚   â”œâ”€â”€ cloud_up.go
â”‚   â”‚   â”œâ”€â”€ cloud_down.go
â”‚   â”‚   â”œâ”€â”€ cloud_destroy.go
â”‚   â”‚   â”œâ”€â”€ cloud_status.go
â”‚   â”‚   â”œâ”€â”€ cloud_connect.go        # Multi-user environment access
â”‚   â”‚   â””â”€â”€ cloud_logs.go
â”‚   â””â”€â”€ pkg/
â”‚       â”œâ”€â”€ engine/                  # NEW: core abstraction layer
â”‚       â”‚   â”œâ”€â”€ spec.go              # EnvironmentSpec (universal format)
â”‚       â”‚   â”œâ”€â”€ parser.go            # Parser interface + auto-detection
â”‚       â”‚   â”œâ”€â”€ runtime.go           # Runtime interface
â”‚       â”‚   â””â”€â”€ detect.go            # Project format detection
â”‚       â”œâ”€â”€ parsers/                 # NEW: format-specific parsers
â”‚       â”‚   â”œâ”€â”€ compose.go           # ComposeParser (wraps existing compose pkg)
â”‚       â”‚   â”œâ”€â”€ devcontainer.go      # DevcontainerParser (Phase 4)
â”‚       â”‚   â””â”€â”€ procfile.go          # ProcfileParser (Phase 6+)
â”‚       â”œâ”€â”€ runtimes/                # NEW: runtime implementations
â”‚       â”‚   â”œâ”€â”€ docker.go            # DockerRuntime (wraps existing runtime pkg)
â”‚       â”‚   â””â”€â”€ podman.go            # PodmanRuntime (Phase 2)
â”‚       â”œâ”€â”€ compose/                 # Existing compose logic
â”‚       â”œâ”€â”€ dns/                     # Existing DNS logic
â”‚       â”œâ”€â”€ models/                  # Existing models
â”‚       â”œâ”€â”€ runtime/                 # Existing Docker runtime
â”‚       â”œâ”€â”€ state/                   # Existing state management
â”‚       â”œâ”€â”€ share/                   # Shared services (separate feature)
â”‚       â””â”€â”€ cloud/                   # Cloud client package
â”‚           â”œâ”€â”€ client.go
â”‚           â”œâ”€â”€ auth.go
â”‚           â”œâ”€â”€ sync.go
â”‚           â”œâ”€â”€ tunnel.go
â”‚           â”œâ”€â”€ privilege.go
â”‚           â””â”€â”€ dns.go
â”‚
â”œâ”€â”€ server/                         # Cloud API server (BSL 1.1)
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â””â”€â”€ server/
â”‚   â”‚       â””â”€â”€ main.go
â”‚   â”œâ”€â”€ pkg/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.go
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.go
â”‚   â”‚   â”‚   â””â”€â”€ handlers/
â”‚   â”‚   â”‚       â”œâ”€â”€ auth.go
â”‚   â”‚   â”‚       â”œâ”€â”€ environments.go
â”‚   â”‚   â”‚       â”œâ”€â”€ machines.go
â”‚   â”‚   â”‚       â”œâ”€â”€ wireguard.go
â”‚   â”‚   â”‚       â””â”€â”€ status.go
â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”‚   â”œâ”€â”€ apikey.go
â”‚   â”‚   â”‚   â””â”€â”€ store.go
â”‚   â”‚   â”œâ”€â”€ vm/
â”‚   â”‚   â”‚   â”œâ”€â”€ pool.go
â”‚   â”‚   â”‚   â”œâ”€â”€ provider.go         # Cloud provider interface
â”‚   â”‚   â”‚   â”œâ”€â”€ manual.go           # Manual/SSH provider (Phase 1)
â”‚   â”‚   â”‚   â”œâ”€â”€ hetzner.go          # Hetzner provider (Phase 1)
â”‚   â”‚   â”‚   â””â”€â”€ health.go
â”‚   â”‚   â”œâ”€â”€ wireguard/
â”‚   â”‚   â”‚   â”œâ”€â”€ keys.go
â”‚   â”‚   â”‚   â”œâ”€â”€ exchange.go         # Multi-peer support
â”‚   â”‚   â”‚   â””â”€â”€ config.go
â”‚   â”‚   â”œâ”€â”€ billing/                # Only when CILO_BILLING_ENABLED=true
â”‚   â”‚   â”‚   â”œâ”€â”€ meter.go
â”‚   â”‚   â”‚   â”œâ”€â”€ pricing.go
â”‚   â”‚   â”‚   â””â”€â”€ store.go
â”‚   â”‚   â””â”€â”€ store/
â”‚   â”‚       â”œâ”€â”€ store.go
â”‚   â”‚       â”œâ”€â”€ postgres.go
â”‚   â”‚       â””â”€â”€ migrations/
â”‚   â””â”€â”€ go.mod
â”‚
â”œâ”€â”€ agent/                          # Machine-side daemon (MIT)
â”‚   â”œâ”€â”€ cmd/
â”‚   â”‚   â””â”€â”€ agent/
â”‚   â”‚       â””â”€â”€ main.go
â”‚   â”œâ”€â”€ pkg/
â”‚   â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.go           # HTTP server (WireGuard interface only)
â”‚   â”‚   â”‚   â”œâ”€â”€ workspace.go
â”‚   â”‚   â”‚   â”œâ”€â”€ environment.go      # Uses engine.Parser + engine.Runtime
â”‚   â”‚   â”‚   â”œâ”€â”€ health.go
â”‚   â”‚   â”‚   â””â”€â”€ wireguard.go        # Multi-peer WireGuard config
â”‚   â”‚   â””â”€â”€ reporter/
â”‚   â”‚       â””â”€â”€ reporter.go
â”‚   â””â”€â”€ go.mod
â”‚
â”œâ”€â”€ action/                         # GitHub Actions (MIT)
â”‚   â”œâ”€â”€ action.yml
â”‚   â”œâ”€â”€ entrypoint.sh
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ packer/                         # VM image build (MIT)
â”‚   â”œâ”€â”€ cilo-vm.pkr.hcl
â”‚   â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ deploy/
â”‚   â”œâ”€â”€ self-host/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env.example
â”‚   â”‚   â”œâ”€â”€ caddy/
â”‚   â”‚   â”‚   â””â”€â”€ Caddyfile
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ hosted/
â”‚       â”œâ”€â”€ docker-compose.yml
â”‚       â””â”€â”€ terraform/
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SELF_HOSTING.md
â”‚   â”œâ”€â”€ SELF_HOST_OPERATIONS.md
â”‚   â”œâ”€â”€ API_REFERENCE.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ SUPPORTED_FORMATS.md        # Compose, devcontainer, Procfile
â”‚   â”œâ”€â”€ SECURITY.md
â”‚   â””â”€â”€ CONTRIBUTING.md             # Community contribution guide
â”‚
â””â”€â”€ LICENSE
```

### 3.4 System Components

```
Developer's Machine                 Self-Hosted or cilocloud.dev
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ cilo CLI         â”‚               â”‚ cilo-server              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚  â”œâ”€â”€ Auth (API keys)     â”‚
â”‚ â”‚ Parser:      â”‚ â”‚â”€â”€â”€HTTPSâ”€â”€â”€â”€â”€â”€â–¶â”‚  â”œâ”€â”€ Machine Pool        â”‚
â”‚ â”‚  auto-detect â”‚ â”‚               â”‚  â”œâ”€â”€ WG Key Exchange     â”‚
â”‚ â”‚ Runtime:     â”‚ â”‚               â”‚  â””â”€â”€ Metering*           â”‚
â”‚ â”‚  docker/     â”‚ â”‚               â”‚         â”‚                â”‚
â”‚ â”‚  podman      â”‚ â”‚               â”‚         â–¼                â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚  Machines                â”‚
â”‚                  â”‚               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ WireGuard â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€encryptedâ”€â”€â–¶â”‚  â”‚ cilo-agent       â”‚   â”‚
â”‚ tunnel           â”‚    tunnel     â”‚  â”‚  â”œâ”€â”€ Parser       â”‚   â”‚
â”‚                  â”‚               â”‚  â”‚  â”œâ”€â”€ Runtime      â”‚   â”‚
â”‚ dnsmasq:         â”‚               â”‚  â”‚  â”œâ”€â”€ WireGuard    â”‚   â”‚
â”‚  *.a1.test       â”‚               â”‚  â”‚  â””â”€â”€ rsync        â”‚   â”‚
â”‚   â†’ remote IPs   â”‚               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   * Metering optional for self-host
```

**cilo CLI** â€” Detects project format, parses into EnvironmentSpec, runs locally via Docker/Podman or delegates to cilo-server for remote execution. Manages WireGuard tunnels and local DNS.

**cilo-server** â€” Go HTTP service. Authenticates via API key, manages machine pool (or static machine list), handles WireGuard key exchange (multi-peer), meters usage optionally. Self-hostable with `docker compose up`.

**cilo-agent** â€” Lightweight daemon on each machine. Receives workspaces via rsync, uses the same Parser + Runtime engine as the CLI to run environments. Reports container IPs and health. Listens only on WireGuard interface.

### 3.5 Two Machine Providers (Both Phase 1)

#### Manual/SSH â€” "Point at Machines You Already Have"

For self-hosting teams with existing servers. No cloud API needed.

```bash
# Register existing machines
docker compose exec server cilo-server machines add \
  --name build-1 --host 192.168.1.100 --ssh-user deploy
```

cilo-server manages assignment and installs cilo-agent over SSH. Doesn't provision or destroy machines â€” they're static.

```go
// server/pkg/vm/manual.go

type ManualProvider struct{}

func (m *ManualProvider) Provision(config ProvisionConfig) (*Machine, error) {
    return nil, fmt.Errorf("manual provider: register machines with 'cilo-server machines add'")
}
func (m *ManualProvider) SetupAgent(machine *Machine) error     // Install agent via SSH
func (m *ManualProvider) HealthCheck(id string) (bool, error)
func (m *ManualProvider) Destroy(id string) error { return nil } // No-op: machines are persistent
```

#### Cloud Provider â€” "Cilo Provisions Machines For You"

Auto-provisioning. Hetzner first (cheapest), AWS later (enterprise demand).

```go
// server/pkg/vm/provider.go

type Provider interface {
    Provision(config ProvisionConfig) (*Machine, error)
    Destroy(providerID string) error
    List() ([]*Machine, error)
    HealthCheck(providerID string) (bool, error)
}
```

### 3.6 Networking: WireGuard with Multi-Peer

Each connection uses a point-to-point WireGuard tunnel. Multiple developers can connect to the same environment (required for PR previews where reviewers need access).

```
Developer A (10.225.0.1) â”€â”€â”
                            â”œâ”€â”€ WireGuard â”€â”€â†’ Machine (10.225.0.100)
Developer B (10.225.0.2) â”€â”€â”˜                  â”‚
                                               â”œâ”€â”€ api       (10.224.1.3)
                                               â”œâ”€â”€ postgres  (10.224.1.4)
                                               â””â”€â”€ redis     (10.224.1.5)
```

Key exchange supports adding/removing peers without disrupting existing connections:

```go
// server/pkg/wireguard/exchange.go

type PeerRegistration struct {
    EnvironmentID string
    UserID        string
    PublicKey     string
    AssignedIP    string    // Unique per peer: 10.225.0.1, 10.225.0.2, etc.
}

func (e *Exchange) AddPeer(machineID string, peer PeerRegistration) error
func (e *Exchange) RemovePeer(machineID string, publicKey string) error
```

### 3.7 WireGuard Privilege Model

Addressed upfront, not deferred.

**Phase 1:** Explicit sudo with clear messaging.

```go
// cilo/pkg/cloud/privilege.go

func CheckWireGuardPrivileges() error {
    if os.Geteuid() != 0 {
        return fmt.Errorf(
            "WireGuard tunnel requires elevated privileges.\n\n" +
            "Run with sudo:\n" +
            "  sudo cilo cloud up agent-1 --from .\n\n" +
            "Why: Creates a WireGuard interface to route traffic to your\n" +
            "remote environment. Requires CAP_NET_ADMIN.\n\n" +
            "See: https://docs.cilo.dev/security#wireguard-privileges")
    }
    return nil
}
```

**Phase 3:** Setuid helper installed during `sudo cilo init` (which already requires sudo for DNS). Minimal binary that only handles WireGuard interface operations. After installation, `cilo cloud up` no longer needs sudo.

**CI mode:** Bypasses WireGuard entirely. Runner accesses VM via public IP with scoped firewall rules. No privilege issues.

### 3.8 DNS Resolution

Local dnsmasq resolves environment DNS names to container IPs, routed through WireGuard for remote environments:

```
curl http://api.agent-1.test
  â†’ dnsmasq: api.agent-1.test â†’ 10.224.1.3
  â†’ routed through WireGuard tunnel (remote) or Docker network (local)
  â†’ hits the api container directly
```

Core invariant: `<service>.<env>.test` always resolves, regardless of where the container runs, what format the project was defined in, or what runtime executes it.

---

## 4. Self-Hosting: Setup and Ongoing Operations

Self-hosting is first-class. The PRD is honest about what's easy and what's ongoing work.

### Initial Setup

```bash
cd deploy/self-host
cp .env.example .env
# Edit .env
docker compose up -d

# Create first API key
docker compose exec server cilo-server admin create-key --scope admin --name "my-key"
```

With Manual/SSH provider (no cloud API needed):
```bash
docker compose exec server cilo-server machines add \
  --name build-1 --host 192.168.1.100 --ssh-user deploy
```

With Hetzner (auto-provisioning):
```bash
# In .env: HETZNER_API_TOKEN=your-token
cd ../../packer && packer build cilo-vm.pkr.hcl
```

Setup time: ~30 minutes (Manual), ~1 hour (Hetzner, includes image build).

### Ongoing Operational Burden

| Task | Frequency | Effort |
|------|-----------|--------|
| cilo-server updates | Monthly | Pull new image, restart. ~5 min. |
| VM image updates | Monthly | Rebuild Packer image, rotate VMs. ~30 min. |
| Database backups | Weekly | Standard pg_dump cron. |
| Monitoring integration | One-time | `/metrics` endpoint, connect to your Prometheus. |
| Pool scaling | As needed | Adjust env vars in .env, restart. |
| Security patches | As announced | Update server, rebuild images. |
| Disk cleanup | Monthly | `cilo doctor --fix` on VMs. |

**The honest tradeoff:** Self-hosting costs 2-4 hours/month of DevOps time. For a team paying a DevOps engineer $150k/year, 3 hours/month â‰ˆ $275/month in labor â€” comparable to the hosted product's team tier. The hosted product is worth it when teams prefer to spend that time on product work.

### Configuration

```bash
# deploy/self-host/.env.example

# Required
POSTGRES_URL=postgres://cilo:password@postgres:5432/cilo
CILO_DOMAIN=cilo.internal.company.com

# Machine Provider
CILO_PROVIDER=manual                # or "hetzner"
HETZNER_API_TOKEN=                  # Only if provider=hetzner

# Pool (cloud providers only)
CILO_POOL_MIN_READY=3
CILO_POOL_MAX_TOTAL=20
CILO_POOL_VM_SIZE=cx31

# Optional
CILO_BILLING_ENABLED=false
CILO_AUTO_DESTROY_HOURS=8
CILO_METRICS_ENABLED=true
```

---

## 5. Data Models

```go
// server/pkg/store/models.go

type Team struct {
    ID        string    `db:"id"`
    Name      string    `db:"name"`
    CreatedAt time.Time `db:"created_at"`
}

type APIKey struct {
    ID        string    `db:"id"`
    TeamID    string    `db:"team_id"`
    KeyHash   string    `db:"key_hash"`      // bcrypt, never exposed
    Prefix    string    `db:"prefix"`        // First 8 chars for identification
    Scope     string    `db:"scope"`         // "admin", "developer", "ci"
    Name      string    `db:"name"`
    CreatedAt time.Time `db:"created_at"`
    LastUsed  time.Time `db:"last_used"`
}

type Environment struct {
    ID          string    `db:"id"`
    TeamID      string    `db:"team_id"`
    Name        string    `db:"name"`         // "agent-1", "pr-42"
    Project     string    `db:"project"`
    Format      string    `db:"format"`       // "compose", "devcontainer", "procfile"
    MachineID   string    `db:"machine_id"`
    Status      string    `db:"status"`
    Subnet      string    `db:"subnet"`
    Services    []Service                      // JSONB
    Peers       []Peer                         // JSONB â€” multiple users can connect
    CreatedAt   time.Time `db:"created_at"`
    CreatedBy   string    `db:"created_by"`
    Source      string    `db:"source"`        // "cli", "ci", "api"
}

// Status: "provisioning" â†’ "syncing" â†’ "running" â†’ "stopped" â†’ "destroying" â†’ "destroyed"

type Service struct {
    Name string `json:"name"`
    IP   string `json:"ip"`
    Port int    `json:"port"`
}

type Peer struct {
    UserID      string    `json:"user_id"`
    WGPublicKey string    `json:"wg_public_key"`
    AssignedIP  string    `json:"assigned_ip"`
    ConnectedAt time.Time `json:"connected_at"`
}

type Machine struct {
    ID           string    `db:"id"`
    ProviderID   string    `db:"provider_id"`
    ProviderType string    `db:"provider_type"`  // "manual", "hetzner", "aws"
    PublicIP     string    `db:"public_ip"`
    WGPublicKey  string    `db:"wg_public_key"`
    WGEndpoint   string    `db:"wg_endpoint"`
    Status       string    `db:"status"`
    AssignedEnv  string    `db:"assigned_env"`
    SSHHost      string    `db:"ssh_host"`       // Manual provider
    SSHUser      string    `db:"ssh_user"`
    Region       string    `db:"region"`
    Size         string    `db:"size"`
    CreatedAt    time.Time `db:"created_at"`
}

// Machine Status: "provisioning" â†’ "ready" â†’ "assigned" â†’ "draining" â†’ "destroying"
// Manual provider: "registering" â†’ "ready" â†’ "assigned" (never "destroying")

type UsageRecord struct {
    ID            string    `db:"id"`
    TeamID        string    `db:"team_id"`
    EnvironmentID string    `db:"environment_id"`
    StartTime     time.Time `db:"start_time"`
    EndTime       time.Time `db:"end_time"`
    DurationSec   int64     `db:"duration_sec"`
}
```

---

## 6. API Endpoints

```
# Authentication
POST   /v1/auth/keys                # Create API key
DELETE /v1/auth/keys/:id             # Revoke
GET    /v1/auth/keys                 # List (admin only)

# Environments
POST   /v1/environments              # Create environment
GET    /v1/environments               # List
GET    /v1/environments/:id           # Details
DELETE /v1/environments/:id           # Destroy
POST   /v1/environments/:id/sync     # Signal workspace sync complete

# Networking
POST   /v1/wireguard/exchange         # Exchange keys (supports multiple peers)
DELETE /v1/wireguard/peers/:key       # Remove peer
GET    /v1/wireguard/status/:id       # Tunnel status

# Machines (Manual provider)
POST   /v1/machines                   # Register
DELETE /v1/machines/:id               # Remove
GET    /v1/machines                   # List

# Operations
GET    /v1/status                     # Instance status
GET    /v1/health                     # Health check
GET    /metrics                       # Prometheus (opt-in)
```

---

## 7. Implementation Plan

### Phase 1: cilo-server + Parser/Runtime Abstraction

**Goal:** Working self-hostable server. Parser and Runtime interfaces defined (Compose is the only implementation, but the abstraction exists).

**Deliverables:**
- cilo-server with auth, environment CRUD, machine pool
- Manual/SSH provider (register existing machines, install agent via SSH)
- Hetzner provider (auto-provision VMs, pool management)
- Parser interface with ComposeParser implementation
- Runtime interface with DockerRuntime implementation
- Self-host Docker Compose setup (`deploy/self-host/`)
- PostgreSQL migrations, API key management

**Server pool manager:**

```go
// server/pkg/vm/pool.go

type PoolConfig struct {
    MinReady int    `env:"CILO_POOL_MIN_READY" default:"3"`
    MaxTotal int    `env:"CILO_POOL_MAX_TOTAL" default:"20"`
    VMSize   string `env:"CILO_POOL_VM_SIZE" default:"cx31"`
    Region   string `env:"CILO_POOL_REGION" default:"nbg1"`
    ImageID  string `env:"CILO_POOL_IMAGE_ID"`
}

func (p *Pool) AssignMachine(envID string) (*Machine, error)
func (p *Pool) ReleaseMachine(machineID string) error
func (p *Pool) Reconcile(ctx context.Context) error               // Cloud providers only
func (p *Pool) RegisterMachine(config ManualMachineConfig) error   // Manual provider
```

---

### Phase 2: cilo-agent + Podman Runtime

**Goal:** Machine-side daemon + Podman as alternative runtime.

**Deliverables:**
- cilo-agent binary (uses same Parser + Runtime as CLI)
- Agent API (WireGuard interface only): `/compose/up`, `/compose/down`, `/compose/status`, `/health`, `/wireguard/add-peer`
- Packer template for VM images
- Agent installation via SSH for Manual provider
- PodmanRuntime implementation

**Agent uses the engine abstraction:**

```go
// agent/pkg/agent/environment.go

import "github.com/sharedco/cilo/cilo/pkg/engine"

func (a *Agent) Up(workspacePath string, envName string) error {
    spec, err := engine.DetectAndParse(workspacePath)
    if err != nil {
        return err
    }
    return a.runtime.Up(spec, envName)
}
```

**Why Podman in Phase 2:** Enterprise teams that can't use Docker (licensing, security policy) get Cilo immediately. The Runtime interface is already defined in Phase 1 â€” Podman is just a second implementation. Minimal incremental cost, real market expansion.

**VM image contents:** Ubuntu 24.04, Docker Engine + Compose plugin, Podman + podman-compose, WireGuard, cilo-agent, rsync, pre-pulled common images (postgres:16-alpine, redis:7-alpine, nginx:alpine, node:20-alpine).

---

### Phase 3: CLI Cloud Extensions + WireGuard Helper

**Goal:** `cilo cloud` subcommands + setuid helper for better UX.

**Commands:**

```bash
# Auth (server URL is always explicit)
cilo cloud login --server https://cilo.company.com
cilo cloud login --server https://api.cilocloud.dev
cilo cloud login --stdin                                  # CI

# Environment lifecycle
cilo cloud up <env> --from <path>
cilo cloud down <env>
cilo cloud destroy <env>
cilo cloud sync <env>

# Multi-user access
cilo cloud connect <env>

# One-shot agent execution
cilo run claude agent-1 "implement auth" --cloud

# Information
cilo cloud status
cilo cloud logs <env> [service]
```

**WireGuard helper:** Installed during `sudo cilo init`. Minimal setuid binary â€” only creates/destroys WireGuard interfaces and manages peers. After installation, `cilo cloud up` works without sudo.

**Auth storage:**

```json
// ~/.cilo/cloud-auth.json (0600)
{
  "server": "https://cilo.internal.company.com",
  "api_key": "cilo_key_abc123...",
  "team_id": "team_xyz"
}
```

---

### Phase 4: CI/CD Integration + Devcontainer Parser

**Goal:** GitHub Actions for PR previews. Devcontainer support broadens the addressable market.

**GitHub Action:**

```yaml
# action/action.yml
name: 'Cilo Environment'
inputs:
  server:
    description: 'Cilo server URL'
    required: true
  api-key:
    required: true
  environment-name:
    required: false
  project-path:
    default: '.'
  action:
    default: 'create'
  timeout:
    default: '60'
outputs:
  environment-url:
  environment-id:
```

**CI mode (`--ci`):** No WireGuard. Direct IP access with scoped firewall rules. Auto-destroy after timeout.

**PR lifecycle:**

```yaml
name: Preview Environment
on:
  pull_request:
    types: [opened, synchronize, reopened, closed]

jobs:
  preview:
    if: github.event.action != 'closed'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: sharedco/cilo-action@v1
        id: preview
        with:
          server: ${{ vars.CILO_SERVER }}
          api-key: ${{ secrets.CILO_API_KEY }}
      - uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ğŸš€ Preview ready: ${{ steps.preview.outputs.environment-url }}`
            })

  cleanup:
    if: github.event.action == 'closed'
    runs-on: ubuntu-latest
    steps:
      - uses: sharedco/cilo-action@v1
        with:
          server: ${{ vars.CILO_SERVER }}
          api-key: ${{ secrets.CILO_API_KEY }}
          action: destroy
```

**DevcontainerParser:** Reads `.devcontainer/devcontainer.json`, converts to EnvironmentSpec. Handles single-container devcontainers, multi-container (via compose reference), and features.

```go
// cilo/pkg/parsers/devcontainer.go

type DevcontainerParser struct{}

func (d *DevcontainerParser) Detect(path string) bool {
    _, err := os.Stat(filepath.Join(path, ".devcontainer", "devcontainer.json"))
    return err == nil
}

func (d *DevcontainerParser) Parse(path string) (*engine.EnvironmentSpec, error) {
    config := readDevcontainerJSON(path)

    // If devcontainer.json references a docker-compose.yml, delegate
    if config.DockerComposeFile != "" {
        return (&ComposeParser{}).Parse(path)
    }

    // Single-container devcontainer â†’ single-service EnvironmentSpec
    return &engine.EnvironmentSpec{
        Services: []engine.ServiceSpec{{
            Name:    "dev",
            Image:   config.Image,
            Build:   parseBuildConfig(config),
            Command: config.PostCreateCommand,
            Ports:   parseForwardPorts(config),
        }},
    }, nil
}
```

This captures the growing Codespaces/Cursor audience. Projects with a `devcontainer.json` work with Cilo automatically â€” no migration needed.

---

### Phase 5: Hosted Product Launch

**Goal:** Launch cilocloud.dev with billing. CLI-only, no dashboard.

**Why no dashboard yet:** At the scale of 10-20 early teams, `cilo cloud status` is sufficient. Engineering time goes to reliability and performance. Build the dashboard when 5+ paying teams request it.

**Billing:**

```go
// server/pkg/billing/meter.go â€” Only active when CILO_BILLING_ENABLED=true

func (m *Meter) Run(ctx context.Context) {
    if !m.enabled { return }
    ticker := time.NewTicker(60 * time.Second)
    for {
        select {
        case <-ticker.C:
            for _, env := range m.store.ListRunningEnvironments() {
                m.store.RecordUsage(UsageRecord{
                    TeamID: env.TeamID, EnvironmentID: env.ID,
                    StartTime: time.Now().Add(-60*time.Second), EndTime: time.Now(),
                    DurationSec: 60,
                })
            }
        case <-ctx.Done():
            return
        }
    }
}
```

**Pricing:**

```go
var DefaultTiers = []Tier{
    {Name: "trial", IncludedHours: 100, MaxConcurrent: 3, TrialDays: 14},
    {Name: "team", MonthlyBase: 4900, IncludedHours: 500, OveragePerHour: 20, MaxConcurrent: 20},
    {Name: "enterprise", OveragePerHour: 15, MaxConcurrent: 100},  // Custom
}
```

**Why trial, not free tier:** A perpetual free tier consumes real VM resources with zero revenue. At early scale with low utilization, idle VMs for free users destroy margins. A 14-day trial qualifies serious buyers. Teams that don't convert can self-host.

**AWS provider (if enterprise demand):** Some paying teams will require AWS. Add here if needed.

---

### Phase 6: Dashboard + Procfile Parser

**Goal:** Dashboard when customers request it. Procfile support for non-containerized apps.

**Dashboard gate:** Only build when 5+ paying teams have asked.

**Dashboard views:**
1. **Environments** â€” Status, creator, duration, format. Stop/destroy.
2. **Environment Detail** â€” Services, IPs, DNS, streamed logs.
3. **Usage** â€” Hours by user, project, time period. CSV export.
4. **Settings** â€” API keys, team config, pool settings.

**ProcfileParser:** Auto-containerizes process-based apps.

```go
// cilo/pkg/parsers/procfile.go

type ProcfileParser struct{}

func (p *ProcfileParser) Parse(path string) (*engine.EnvironmentSpec, error) {
    procs := parseProcfile(filepath.Join(path, "Procfile"))
    spec := &engine.EnvironmentSpec{}
    for name, command := range procs {
        spec.Services = append(spec.Services, engine.ServiceSpec{
            Name:    name,
            Build:   autoDetectBuild(path),  // Detect runtime, generate Dockerfile
            Command: strings.Fields(command),
        })
    }
    return spec, nil
}

// autoDetectBuild inspects the project for package.json, requirements.txt,
// Gemfile, go.mod, etc. and generates an appropriate build context.
func autoDetectBuild(path string) *engine.BuildSpec { ... }
```

---

## 8. Data Flow

### `cilo cloud up agent-1 --from .`

```
Step 1: CLI detects project format
  engine.DetectAndParse(".") â†’ EnvironmentSpec (compose, 4 services)

Step 2: CLI â†’ cilo-server
  POST /v1/environments { name: "agent-1", project: "myapp", format: "compose" }
  â† { id: "env-abc", machine: { public_ip, wg_endpoint, wg_public_key } }

Step 3: CLI â€” WireGuard
  Generate keypair â†’ POST /v1/wireguard/exchange { env_id, client_public_key }
  Configure local interface via helper (no sudo needed after Phase 3)
  Add route: 10.224.1.0/24 via cilo0

Step 4: CLI â†’ Machine (via tunnel)
  rsync workspace to 10.225.0.100:~/.cilo/envs/myapp/agent-1/

Step 5: CLI â†’ cilo-agent (via tunnel)
  POST http://10.225.0.100:8080/environment/up

Step 6: cilo-agent
  engine.DetectAndParse(workspace) â†’ EnvironmentSpec
  runtime.Up(spec, "agent-1") â†’ containers running
  Report service IPs to cilo-server

Step 7: CLI â† cilo-server
  GET /v1/environments/env-abc â†’ { services: [...], peers: [...] }

Step 8: CLI â€” DNS
  dnsmasq: api.agent-1.test â†’ 10.224.1.3

Step 9: CLI â†’ stdout
  "Environment agent-1 is ready (compose, 4 services)"
  "  api:      http://api.agent-1.test"
  "  nginx:    http://nginx.agent-1.test"
  "  postgres: postgres.agent-1.test:5432"
```

### `cilo cloud connect agent-1` (Second User)

```
Step 1: CLI â†’ cilo-server
  POST /v1/wireguard/exchange { env_id: "env-abc", client_public_key: "new-key" }
  â† { assigned_ip: "10.225.0.2", machine_wg_public_key, wg_endpoint }

Step 2: cilo-server â†’ cilo-agent
  POST /wireguard/add-peer { public_key: "new-key", assigned_ip: "10.225.0.2" }

Step 3: CLI â€” WireGuard + DNS
  Configure interface, same DNS entries as original creator.

Result: Second developer sees identical environment at identical DNS names.
```

---

## 9. Security

**Authentication:** API keys scoped to `admin`, `developer`, `ci`. bcrypt hashed. All requests require `Authorization: Bearer <key>`.

**Network:** WireGuard end-to-end encryption. cilo-agent listens only on WireGuard interface. Machines firewalled to WireGuard (51820/UDP) + SSH (22/TCP, server management only).

**Isolation:** One environment per machine (v1). Docker/Podman networks isolated per environment. Machine wiped between assignments (cloud) or environment directory cleaned (Manual).

**Secrets:** Developer keys in `~/.cilo/cloud-auth.json` (0600). Server credentials via environment variables. No secrets in VM images.

**Privilege escalation:** WireGuard helper is a minimal setuid binary with strict input validation. Only handles interface operations. Source available for audit.

---

## 10. Operations

**Auto-Cleanup:** Idle environments destroyed after `CILO_AUTO_DESTROY_HOURS` (default: 8). CI environments after `--timeout` (default: 60 min). Cloud VMs recycled within 60 seconds. Manual machines cleaned but not destroyed.

**Failure Recovery:** Machine unhealthy â†’ mark degraded, notify user. Server down â†’ existing tunnels keep working. Tunnel drops â†’ WireGuard auto-reconnects.

**Monitoring:** Prometheus metrics on `/metrics`. API latency/errors, machine pool utilization, active tunnels, environment creation rate, average lifetime, format distribution (compose vs devcontainer vs procfile).

---

## 11. Success Metrics

| Phase | Metric | Target |
|-------|--------|--------|
| 1-3 | `cilo cloud up` to DNS-accessible | < 60 seconds |
| 1-3 | Workspace sync (< 500MB) | < 30 seconds |
| 1-3 | Self-host setup (Manual provider) | < 30 minutes |
| 1-3 | Self-hosted teams validating | 5+ |
| 2 | Podman runtime parity with Docker | Feature-complete |
| 4 | GitHub Action preview creation | < 90 seconds |
| 4 | Devcontainer projects auto-detected | 100% of standard configs |
| 5 | Trial â†’ paid conversion | > 20% |
| 5 | Paying teams within 3 months | 10+ |
| 5 | Weekly environment-hours | 1,000+ |
| 6 | Dashboard requested by paying teams | 5+ before building |

---

## 12. Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Docker Compose usage declines among early adopters | Shrinking primary market | Parser abstraction enables devcontainer + Procfile without refactoring |
| Coder ships `--from-compose` flag | Direct feature parity on remote Compose | Local + remote isolation is a deeper moat; Coder's Terraform architecture makes Compose a bolt-on, not native |
| AI agent market takes 2+ years | Growth play delayed | Lead with general isolation value; agents are a use case, not the product |
| Self-hosting too easy â†’ low hosted conversion | Revenue ceiling | Operational burden is honest in docs; hosted value is pre-warmed pools + zero-config + scale management |
| Small team operating distributed platform | Reliability, burnout | Manual provider reduces infra to manage; phased launch limits blast radius |
| Podman ecosystem less mature than Docker | Runtime parity issues | Docker remains primary; Podman is additive for enterprise |
| Devcontainer spec evolves rapidly | Parser maintenance burden | Track spec changes; community contributions help |

---

## 13. Community Strategy

The moat isn't network effects (Cilo has none). It's community. The product is only defensible if contributors build around the format-agnostic workflow.

**What gets contributed:**
- New parsers (format support for new project types)
- New runtime implementations (containerd, etc.)
- Cloud provider plugins (DigitalOcean, Vultr, OVH)
- CI/CD integrations (GitLab CI, Bitbucket Pipelines, CircleCI)
- Compose optimizations (image caching, layer sharing)

**Where contributors engage:**
- GitHub Issues + Discussions (primary)
- Discord (real-time help, feature discussion)
- `CONTRIBUTING.md` with clear "good first issue" labels

**Governance:**
- Parser and Runtime interfaces are stable APIs â€” breaking changes require RFC
- Community parsers can live in-tree or as external plugins
- Core team maintains Compose, Podman, Devcontainer; community maintains the rest

**What keeps community loyal:**
- BSL â†’ Apache conversion means the code is eventually fully open
- MIT license on CLI and agent removes all friction
- Self-hosting works without any vendor dependency
- Parser/Runtime plugin architecture means contributors own their code

---

## 14. Open Decisions

| Decision | Recommendation | Resolve By |
|----------|----------------|------------|
| One machine per env vs multi-tenant | Single-tenant v1 | Phase 1 |
| WireGuard helper implementation | Setuid binary, security audit before release | Phase 3 |
| Cloud providers | Hetzner + Manual v1. AWS when enterprise demands. | Phase 1 |
| Database | PostgreSQL | Phase 1 |
| Preview URL domain | Configurable `CILO_DOMAIN`. Hosted uses `cilocloud.dev`. | Phase 4 |
| Dashboard framework | React SPA. Only build when 5+ teams request. | Phase 6 |
| Procfile auto-containerization strategy | Nixpacks vs custom Dockerfile generation | Phase 6 |
| Devcontainer feature support depth | Core features only vs full spec | Phase 4 |

---

## 15. Out of Scope

- **Mesh networking / Headscale / DERP** â€” Point-to-point WireGuard is sufficient.
- **Hybrid local + remote** â€” Separate roadmap. Requires shared services first.
- **Browser IDE / terminal** â€” Not a Coder/Codespaces competitor.
- **Continuous file sync** â€” Sync is explicit. Use Mutagen alongside if needed.
- **Container migration** â€” Destroy and recreate.
- **Multi-region** â€” Single region v1.
- **Dashboard before Phase 6** â€” CLI and API are sufficient for early customers.
- **Kubernetes as input format** â€” Directly competes with Coder/Tilt/Skaffold. Avoid.
- **Terraform as input format** â€” This is Coder's core. Not our territory.
- **Nix/devenv support** â€” Process-level isolation is architecturally different. Revisit if demand materializes.